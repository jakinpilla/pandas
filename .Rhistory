issubclass(pd.RangeIndex, pd.Index)
## pandas.core.indexes.base.Index  : package name, modules path, type
## pandas index object
## RangeIndex is similer to python's range object.
## because it is exactly defined only by start value, last value and step value,
## so only less memory is needed
movie.dtypes
#%%
movie.get_dtype_counts()
#%%
movie['director_name']
#%%
movie.director_name
#%%
type(movie['director_name'])
#%%
director = movie['director_name']
director.name ## return "director_name"
#%%
director.to_frame()
#%%
s_attr_methods = set(dir(pd.Series))
len(s_attr_methods)
#%%
df_attr_methods = set(dir(pd.DataFrame))
len(df_attr_methods)
#%%
len(s_attr_methods & df_attr_methods)
#%%
movie = pd.read_csv('./data/movie.csv')
director = movie['director_name']
actor_1_fb_likes = movie['actor_1_facebook_likes']
actor_1_fb_likes
director.head()
#%%
actor_1_fb_likes.head()
#%%
director.value_counts()
#%%
actor_1_fb_likes.value_counts()
#%%
director.size
director.shape
len(director)
#%%
director.count() ## not counting "nan"
#%%
actor_1_fb_likes.count()
actor_1_fb_likes.min(), actor_1_fb_likes.max(), actor_1_fb_likes.mean(), actor_1_fb_likes.median(), \
actor_1_fb_likes.std(), actor_1_fb_likes.sum()
#%%
actor_1_fb_likes.describe()
#%%
actor_1_fb_likes.quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])
#%%
director.isnull()
#%%
director.value_counts().head(3)
actor_1_fb_likes.isnull().sum()
actor_1_fb_likes.dtype
actor_1_fb_likes.fillna(0)\
.astype(int)\
.head()
#%%
actor_1_fb_likes.count()
actor_1_fb_likes.min(), actor_1_fb_likes.max(), actor_1_fb_likes.mean(), actor_1_fb_likes.median(), \
actor_1_fb_likes.std(), actor_1_fb_likes.sum()
#%%
actor_1_fb_likes.describe()
#%%
actor_1_fb_likes.quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])
#%%
director.isnull()
#%%
director.value_counts().head(3)
actor_1_fb_likes.isnull().sum()
actor_1_fb_likes.dtype
actor_1_fb_likes.fillna(0)\
.astype(int)\
.head()
actor_1_fb_likes.isnull
(actor_1_fb_likes.fillna(0)
.astype(int)
.head())
movie = pd.read_csv("./data/movie.csv")
movie2 = movie.set_index("movie_title")
movie2.head()
movie = pd.read_csv("./data/movie.csv", index_col = "movie_title")
movie2 = movie2.reset_index()
movie2.head()
movie = pd.read_csv("./data/movie.csv", index_col = "movie_title")
movie
movie2 = movie2.reset_index()
movie2.head()
idx_rename = {"Avatar" : "Ravatar", "Spectre" : "Ertceps"}
col_rename = {"director_name" : "Director Name",
"num_critic_for_reviews" : "Critical Reviews"}
movie_renamed = movie.rename(index = idx_rename,
columns = col_rename)
movie_renamed.head()
movie = pd.read_csv("./data/movie.csv", index_col = "movie_title")
index = movie.index
columns = movie.columns
index_list =index.tolist()
column_list = columns.tolist()
index_list[0] = 'Ravata'
index_list[2] = 'Ertceps'
column_list[1] = 'Director Name'
column_list[2] = 'Critical Reviews'
print(index_list)
movie = pd.read_csv("./data/movie.csv", index_col = "movie_title")
index = movie.index
columns = movie.columns
index_list =index.tolist()
column_list = columns.tolist()
index_list
column_list
index_list[0] = 'Ravata'
index_list[2] = 'Ertceps'
column_list[1] = 'Director Name'
column_list[2] = 'Critical Reviews'
print(index_list)
index_list
movie = pd.read_csv("./data/movie.csv")
movie["has_seen"] = 0
movie["actor_director_facebook_likes"] =\
(movie["actor_1_facebook_likes"] +
movie["actor_2_facebook_likes"] +
movie["actor_3_facebook_likes"] +
movie["director_facebook_likes"])
movie["actor_director_facebook_likes"].isnull().sum()
movie["actor_director_facebook_likes"] = \
movie["actor_director_facebook_likes"].fillna(0)
movie["is_cast_likes_more"] = \
(movie["cast_total_facebook_likes"] >=
movie["actor_director_facebook_likes"])
movie["is_cast_likes_more"].all()
movie = movie.drop("actor_director_facebook_likes", axis = "columns")
movie["actor_total_facebook_likes"] = \
(movie["actor_1_facebook_likes"] +
movie["actor_2_facebook_likes"] +
movie["actor_3_facebook_likes"])
movie["actor_total_facebook_likes"] = movie["actor_total_facebook_likes"].fillna(0)
movie["is_cast_likes_more"] = \
(movie["cast_total_facebook_likes"] >=
movie["actor_total_facebook_likes"])
movie["is_cast_likes_more"].all()
movie["pct_actor_cast_like"]  = \
(movie["actor_total_facebook_likes"] / movie["cast_total_facebook_likes"])
(movie["pct_actor_cast_like"].min(), movie["pct_actor_cast_like"].max())
movie.set_index("movie_title")["pct_actor_cast_like"].head()
profit_index = movie.columns.get_loc('gross') + 1
profit_index
movie.insert(loc = profit_index,
column = 'profit',
value = movie['gross'] - movie['budget'])
movie["actor_director_facebook_likes"] =\
(movie["actor_1_facebook_likes"] +
movie["actor_2_facebook_likes"] +
movie["actor_3_facebook_likes"] +
movie["director_facebook_likes"])
movie["actor_director_facebook_likes"].isnull().sum()
movie["actor_director_facebook_likes"] = \
movie["actor_director_facebook_likes"].fillna(0)
del movie['actor_director_facebook_likes']
## selecting multiful columns
movie_actor_director = movie[['actor_1_name', 'actor_2_name',
'actor_3_name', 'director_name']]
movie_actor_director.head()
movie[['director_name']].head()
cols = ['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name']
movie_actor_director = movie[cols]
tuple1 = 1, 2, 3, 'a', 'b'
tuple2 = (1, 2, 3, 'a', 'b')
tuple1 == tuple2
movie = pd.read_csv("./data/movie.csv", index_col = "movie_title")
movie.get_dtype_counts()
movie.select_dtypes(include = ['int64']).head()
movie.select_dtypes(include = ['number']).head()
movie.filter(like='facebook').head()
movie.filter(regex = '\d').head()
movie.filter(like='facebook').columns
movie.filter(regex = '\d').columns
movie.filter(items = ['actor_1_name', 'asdf']).head() # not raising KeyError
## arranging columns
## seperate discrete and continuous columns
## grouping commnon columns
## arrange the most important column first within grouped columns
movie = pd.read_csv("./data/movie.csv")
movie.head()
movie.columns
movie.info()
movie.select_dtypes(include = ['object']).columns
movie['content_rating'][:5]
disc_core = ['movie_title', 'title_year', 'content_rating', 'genres']
disc_people = ['director_name', 'actor_1_name', 'actor_2_name',
'actor_3_name']
disc_other = ['color', 'country', 'language', 'plot_keywords', 'movie_imdb_link']
cont_fb = ['director_facebook_likes', 'actor_1_facebook_likes',
'actor_2_facebook_likes', 'actor_3_facebook_likes',
'cast_total_facebook_likes', 'movie_facebook_likes']
cont_finance = ['budget', 'gross']
cont_num_reviews = ['num_voted_users', 'num_user_for_reviews',
'num_critic_for_reviews']
cont_other = ['imdb_score', 'duration', 'aspect_ratio', 'facenumber_in_poster']
new_col_order = disc_core + disc_people + \
disc_other + cont_fb + cont_finance + cont_num_reviews + cont_other
set(movie.columns) == set(new_col_order)
movie2 = movie[new_col_order]
movie2.head()
movie2.columns
movie = pd.read_csv("./data/movie.csv")
movie.shape
movie.size
movie.ndim
len(movie)
movie.count()
movie.describe()
movie.describe(percentiles = [.01, .3, .99])
movie.min(skipna = False)
movie.min()
movie.isnull().sum()
movie.isnull().sum().sum()
movie.isnull().any()
movie.isnull().any().any()
movie.isnull().get_dtype_counts()
movie.select_dtypes(['object']).fillna('').min()
movie.select_dtypes(['object'])\
.fillna('')\
.min()
college = pd.read_csv("./data/college.csv")
# college + 5
college = pd.read_csv("./data/college.csv", index_col = "INSTNM")
college_ugds_ = college.filter(like = "UGDS_")
college_ugds_.head()
college_ugds_ + 0.00501
(college_ugds_ + 0.00501) // 0.01
college_ugds_op_round = (college_ugds_ + 0.00501) // 0.01 / 100
college_ugds_op_round.head()
college_ugds_round = (college_ugds_ + .00001).round(2)
college_ugds_op_round.equals(college_ugds_round)
college_ugds_op_round_methods = college_ugds_.add(.00501)\
.floordiv(.01)\
.div(100)
college_ugds_op_round_methods.equals(college_ugds_op_round)
col_stop
movie = pd.read_csv("./data/movie.csv")
movie.shape
movie.size
movie.ndim
len(movie)
movie.count()
movie.describe()
movie.describe()
reticulate::repl_python()
reticulate::repl_python()
from os import getcwd, chdir
wd = getcwd()
chdir(wd)
getcwd()
import numpy as np
import datetime
import matplotlib.pyplot as plt
#m pandas option setting to see more columns
import pandas as pd
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
date = datetime.date(year=2013, month=6, day=7)
time = datetime.time(hour=12, minute=30, second=19, microsecond=463198)
dt=datetime.datetime(year=2013, month=6, day=7, hour=12, minute=30, second=19,
microsecond=463198)
print('date is ', date)
print('time is ', time)
print('datetime is ', dt)
td = datetime.timedelta(weeks=2, days=5, hours=10, minutes=20, seconds=6.73,
milliseconds=99, microseconds=8)
print(td)
print('new date is', date+td)
print('new datetime is', dt+td)
pd.Timestamp(year=2012, month=12, day=21, hour=5, minute=10, second=8,
microsecond=99)
pd.Timestamp('2016/1/10')
pd.Timestamp('2014-5/10')
pd.Timestamp('Jan 3, 2019 20:45.56')
pd.Timestamp('2016-01-05T05:34:43.123456789')
pd.Timestamp(500)
pd.Timestamp(5000, unit='D')
pd.to_datetime('2015-5-13')
pd.to_datetime('2015-13-5', dayfirst=True)
pd.to_datetime('Start Date: Sep 30, 2017 Start Time: 1:30 pm',
format='Start Date: %b %d, %Y Start Time: %I:%M %p')
pd.to_datetime('2017-04-11 00:00:00')
s = pd.Series([10, 100, 1000, 10000])
pd.to_datetime(s, unit='D')
s= pd.Series(['12-5-2015', '14-1-2013', '20/12/2017', '40/23/2017'])
pd.to_datetime(s, dayfirst=True, errors='coerce')
pd.to_datetime(['Aug 3 1999 3:45:56', '10/31/2017'])
# Timedelta
pd.Timedelta('12 days 5 hours 3 minutes 123456789 nanoseconds')
pd.Timedelta(days=5, minutes=7.34)
pd.Timedelta(100, unit='W')
pd.to_timedelta('67:15:45.454')
s = pd.Series([10, 100])
pd.to_timedelta(s, unit='s')
time_strings = ['2 days 24 minutes 89.67 seconds', '00:45:23.6']
pd.to_timedelta(time_strings)
pd.Timedelta('12 days 5 hours 3 minutes')*2
pd.Timestamp('1/1/2017') + \
pd.Timedelta('12 days 5 hours 3 minutes')*2
td1 = pd.to_timedelta([10, 100], unit='s')
td2 = pd.to_timedelta(['3 hours', '4 hours'])
td1 + td2
pd.Timedelta('12 days') / pd.Timedelta('3 days')
ts = pd.Timestamp('2016-10-1 4:23:23.9')
ts.ceil('h')
ts.year, ts.month, ts.day, ts.hour, ts.minute, ts.second
ts.dayofweek, ts.dayofyear, ts.daysinmonth
ts.to_pydatetime()
td = pd.Timedelta(125.8723, unit='h')
td
td.round('min')
td.components
td.total_seconds()
date_string_list=['Sep 30 1984']*10000
pd.to_datetime(date_string_list, format='%b %d %Y')
pd.to_datetime(date_string_list)
crime = pd.read_hdf('./data/crime.h5', 'crime')
crime.dtypes
crime = crime.set_index('REPORTED_DATE')
crime.head()
crime.loc['2016-05-12 16:45:00']
crime.loc['2016-05-12']
crime.loc['2015-05'].shape
crime.loc['2016'].shape
crime.loc['2016-05-12 03']
crime.loc['Dec 2015'].sort_index()
crime.loc['2016 Sep, 15'].shape
crime.loc['21st October 2014 05'].shape
crime.loc['2015-3-4':'2016-1-1'].sort_index()
crime.loc['2015-3-4 22' : '2016-1-1 11:45:00'].sort_index()
crime.loc['2015-3-4':'2016-1-1']
crime_sort = crime.sort_index()
crime_sort.loc['2015-3-4':'2016-1-1']
crime=pd.read_hdf('./data/crime.h5', 'crime').set_index('REPORTED_DATE')
print(type(crime.index))
crime.between_time('2:00', '5:00', include_end=False).head()
crime.at_time('5:47').head()
crime_sort = crime.sort_index()
crime_sort.first(pd.offsets.MonthBegin(6))
## 1 row :: 2012-07-01 :: why?? 6 min?
crime_sort.first(pd.offsets.MonthEnd(6))
crime_sort.first(pd.offsets.MonthBegin(6, normalize=True))
crime_sort.loc[:'2012-06']
crime_sort.first('5D')
crime_sort.first('5B')
crime_sort.first('7W')
crime_sort.first('3QS')
crime_sort.first('A')
crime_sort = pd.read_hdf('./data/crime.h5', 'crime')\
.set_index('REPORTED_DATE')\
.sort_index()
crime_quarterly = crime_sort.resample('Q')['IS_CRIME', 'IS_TRAFFIC'].sum()
crime_quarterly.head()
crime_sort.resample('QS')['IS_CRIME', 'IS_TRAFFIC'].sum().head()
crime_sort.loc['2012-4-1':'2012-6-30', ['IS_CRIME', 'IS_TRAFFIC']].sum()
crime_quarterly2 = crime_sort.groupby(pd.Grouper(freq='Q'))\
['IS_CRIME', 'IS_TRAFFIC'].sum()
crime_quarterly2.equals(crime_quarterly)
plot_kwargs = dict(figsize=(16, 4),
color = ['black', 'lightgrey'],
title='Denver Crimes and Traffic Accidents')
crime_quarterly.plot(**plot_kwargs)
crime_sort.resample('QS-MAR')['IS_CRIME', 'IS_TRAFFIC']\
.sum().head()
crime_begin = crime_quarterly.iloc[0]
crime_begin
crime_quarterly.div(crime_begin).sub(1).round(2).plot(**plot_kwargs)
crime=pd.read_hdf('./data/crime.h5', 'crime')
crime.head()
wd_counts=crime['REPORTED_DATE'].dt.weekday_name.value_counts()
wd_counts
days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',
'Sunday']
title = 'Denver Crimes and Traffic Accidents per Weekday'
wd_counts.reindex(days).plot(kind='barh', title=title)
title='Denver Crimes and Traffic Accidents per Year'
crime['REPORTED_DATE'].dt.year.value_counts().sort_index()\
.plot(kind='barh', title=title)
weekday = crime['REPORTED_DATE'].dt.weekday_name
days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',
'Sunday']
title = 'Denver Crimes and Traffic Accidents per Weekday'
wd_counts.reindex(days).plot(kind='barh', title=title)
import numpy as np
import datetime
import matplotlib.pyplot as plt
#m pandas option setting to see more columns
import pandas as pd
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'C:/Anaconda3/Library/plugins/platforms'
date = datetime.date(year=2013, month=6, day=7)
time = datetime.time(hour=12, minute=30, second=19, microsecond=463198)
dt=datetime.datetime(year=2013, month=6, day=7, hour=12, minute=30, second=19,
microsecond=463198)
print('date is ', date)
print('time is ', time)
print('datetime is ', dt)
td = datetime.timedelta(weeks=2, days=5, hours=10, minutes=20, seconds=6.73,
milliseconds=99, microseconds=8)
print(td)
print('new date is', date+td)
print('new datetime is', dt+td)
pd.Timestamp(year=2012, month=12, day=21, hour=5, minute=10, second=8,
microsecond=99)
pd.Timestamp('2016/1/10')
pd.Timestamp('2014-5/10')
pd.Timestamp('Jan 3, 2019 20:45.56')
pd.Timestamp('2016-01-05T05:34:43.123456789')
pd.Timestamp(500)
pd.Timestamp(5000, unit='D')
pd.to_datetime('2015-5-13')
pd.to_datetime('2015-13-5', dayfirst=True)
pd.to_datetime('Start Date: Sep 30, 2017 Start Time: 1:30 pm',
format='Start Date: %b %d, %Y Start Time: %I:%M %p')
pd.to_datetime('2017-04-11 00:00:00')
s = pd.Series([10, 100, 1000, 10000])
pd.to_datetime(s, unit='D')
s= pd.Series(['12-5-2015', '14-1-2013', '20/12/2017', '40/23/2017'])
pd.to_datetime(s, dayfirst=True, errors='coerce')
pd.to_datetime(['Aug 3 1999 3:45:56', '10/31/2017'])
# Timedelta
pd.Timedelta('12 days 5 hours 3 minutes 123456789 nanoseconds')
pd.Timedelta(days=5, minutes=7.34)
pd.Timedelta(100, unit='W')
pd.to_timedelta('67:15:45.454')
s = pd.Series([10, 100])
pd.to_timedelta(s, unit='s')
time_strings = ['2 days 24 minutes 89.67 seconds', '00:45:23.6']
pd.to_timedelta(time_strings)
pd.Timedelta('12 days 5 hours 3 minutes')*2
pd.Timestamp('1/1/2017') + \
pd.Timedelta('12 days 5 hours 3 minutes')*2
td1 = pd.to_timedelta([10, 100], unit='s')
td2 = pd.to_timedelta(['3 hours', '4 hours'])
td1 + td2
pd.Timedelta('12 days') / pd.Timedelta('3 days')
ts = pd.Timestamp('2016-10-1 4:23:23.9')
ts.ceil('h')
ts.year, ts.month, ts.day, ts.hour, ts.minute, ts.second
ts.dayofweek, ts.dayofyear, ts.daysinmonth
ts.to_pydatetime()
td = pd.Timedelta(125.8723, unit='h')
td
td.round('min')
td.components
td.total_seconds()
date_string_list=['Sep 30 1984']*10000
# pd.to_datetime(date_string_list, format='%b %d %Y')
pd.to_datetime(date_string_list)
crime = pd.read_hdf('./data/crime.h5', 'crime')
crime.dtypes
crime = crime.set_index('REPORTED_DATE')
crime.head()
crime.loc['2016-05-12 16:45:00']
crime.loc['2016-05-12']
crime.loc['2015-05'].shape
crime.loc['2016'].shape
crime.loc['2016-05-12 03']
crime.loc['Dec 2015'].sort_index()
crime.loc['2016 Sep, 15'].shape
crime.loc['21st October 2014 05'].shape
crime.loc['2015-3-4':'2016-1-1'].sort_index()
crime.loc['2015-3-4 22' : '2016-1-1 11:45:00'].sort_index()
crime.loc['2015-3-4':'2016-1-1']
crime_sort = crime.sort_index()
crime_sort.loc['2015-3-4':'2016-1-1']
crime=pd.read_hdf('./data/crime.h5', 'crime').set_index('REPORTED_DATE')
print(type(crime.index))
crime.between_time('2:00', '5:00', include_end=False).head()
crime.at_time('5:47').head()
crime.at_time('5:47').head()
crime_sort = crime.sort_index()
crime_sort.first(pd.offsets.MonthBegin(6))
## 1 row :: 2012-07-01 :: why?? 6 min?
crime_sort.first(pd.offsets.MonthEnd(6))
crime_sort.first(pd.offsets.MonthBegin(6, normalize=True))
crime_sort.loc[:'2012-06']
crime_sort.first('5D')
crime_sort.first('5B')
crime_sort.first('7W')
crime_sort.first('3QS')
crime_sort.first('A')
crime_sort = pd.read_hdf('./data/crime.h5', 'crime')\
.set_index('REPORTED_DATE')\
.sort_index()
crime_quarterly = crime_sort.resample('Q')['IS_CRIME', 'IS_TRAFFIC'].sum()
crime_quarterly.head()
crime_sort.resample('QS')['IS_CRIME', 'IS_TRAFFIC'].sum().head()
crime_sort.loc['2012-4-1':'2012-6-30', ['IS_CRIME', 'IS_TRAFFIC']].sum()
crime_quarterly2 = crime_sort.groupby(pd.Grouper(freq='Q'))\
['IS_CRIME', 'IS_TRAFFIC'].sum()
crime_quarterly2.equals(crime_quarterly)
plot_kwargs = dict(figsize=(16, 4),
color = ['black', 'lightgrey'],
title='Denver Crimes and Traffic Accidents')
crime_quarterly.plot(**plot_kwargs)
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'C:/Anaconda3/Library/plugins/platforms'
